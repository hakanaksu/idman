#!/usr/bin/env python
# -*- coding: utf-8 -*-

import sys
import json
import re


# Helper for set-Encoding in json  (to list)
class SetEncoder(json.JSONEncoder):
    def default(self, obj):
        """

        :param obj:
        :return:
        """
        if isinstance(obj, set):
            return list(obj)
        return json.JSONEncoder.default(self, obj)


# Helper Function for only adding non-falsy values
def addToSet(set1, el):
    """

    :param set1:
    :param el:
    :return:
    """
    if not el:
        return set1
    elif isinstance(el, basestring) and not re.sub("[^\w]", "",
                                                   el).strip():  # drop values without alphanumeric characters
        return set1
    else:
        set1.add(el)
        return set1


# Adds the developers participating at the commit to the commit
def learnDev(dataset, com):
    """

    :param dataset:
    :param com:
    :return:
    """
    commit = json.loads(com)
    dataset = processSingleDev(dataset, commit['author_name'], commit['author_mail'])
    dataset = processSingleDev(dataset, commit['committer_name'], commit['committer_mail'],
                               commit['signer'],
                               commit['signer_key'])
    return dataset


# Tries to find exsisting developer in dataset and adds him if not found
def processSingleDev(dataset, name, mail, signer=None, skey=None):
    """

    :param dataset:
    :param name:
    :param mail:
    :param signer:
    :param skey:
    :return:
    """
    for d in dataset:
        if name in d['Names'] or isEMailSim(mail, d) or signer in d['Names'] or skey in d['Keys']:
            addToSet(d['Names'], name)
            addToSet(d['Names'], signer)  # Signer makes commit
            addToSet(d['Mails'], mail)
            addToSet(d['Mailusers'], mail.split('@')[0])
            addToSet(d['Keys'], skey)
            return dataset
    tmp = {
        'Names': addToSet(set(), name), 'Mails': addToSet(set(), mail),
        'Mailusers': addToSet(set(), mail.split('@')[0])
    }
    addToSet(tmp['Names'], signer)
    tmp['Keys'] = addToSet(set(), skey)
    dataset.append(tmp)
    return dataset


# searches for email-user in exsisting usernames and emails
def isEMailSim(email1, data):
    """

    :param email1:
    :param data:
    :return:
    """
    if not isinstance(email1, basestring):
        return False
    username = email1.split("@")[0]
    for mail in data['Mailusers']:
        if mail == username:
            return True
    for name in data['Names']:
        if username == name:
            return True
    return False


# combines Elements of the dataset if they share values
# ATTENTION: deletes the given dataset
def combineElements(dataset):
    """

    :param dataset:
    :return:
    """
    newdata = []
    for d in dataset[:]:
        try:
            dataset.remove(d)
            tmp = d
            for comp in dataset[:]:
                if len(dictIntersection(d, comp)):
                    tmp = dictUnion(tmp, comp)
                    try:
                        dataset.remove(comp)
                    except ValueError:
                        pass
            newdata.append(tmp)
            # print tmp
        except ValueError:
            continue
    return newdata


# Intersects dictionaries interpreting values as set
def dictIntersection(d1, d2):
    """

    :param d1:
    :param d2:
    :return:
    """
    result = {}
    for k in set(d1.keys()).intersection(set(d2.keys())):
        result[k] = set(d1[k]).intersection(set(d2[k]))
        if not result[k]:
            del result[k]
    return result


# Intersects dictionaries interpreting values as set
def dictUnion(d1, d2):
    """

    :param d1:
    :param d2:
    :return:
    """
    result = {}
    for k in set(d1.keys()).union(set(d2.keys())):
        result[k] = set(d1.get(k, [])).union(set(d2.get(k, [])))
        if not result[k]:
            del result[k]
    return result


if __name__ == "__main__":
    dataset = []
    # inital data aquisition
    for line in sys.stdin:
        dataset = learnDev(dataset, line)
    # minimize dataset
    dsize = 0
    while not dsize == len(dataset):  # combination is not noop
        dsize = len(dataset)
        dataset = combineElements(dataset)
    for line in dataset:
        print json.dumps(line, cls=SetEncoder)
